{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c269f4-b586-4bd7-9fc5-105332ea5ef4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a QnA Agent and Promote to LLM Model Registry\n",
    "Author: `Max.AI`\n",
    "\n",
    "This document presents a detailed overview of building agent using Max LLM Components.\n",
    "\n",
    "**Components**:\n",
    "- **Purpose and Design**: The MaxAgentQA is crafted for question-answering tasks. It captures the advanced capabilities of retrieval-augmented generation, which combines the retrieval of relevant information with sophisticated language generation models.\n",
    " - **Configuration Requirements**: To effectively utilize this agent, the user needs to provide specific configurations. These include settings for the Language Large Model (LLM), VectorDB, MaxFlow Configuration. The LLM configuration would define how the model processes and generates language responses, while the VectorDB configuration would pertain to how the system handles and retrieves vectorized data representations.The MaxFlow configuration would enable monitoring and logging.\n",
    "- **Key Methods**:\n",
    "> - `add()`: This method is likely designed for adding or indexing new data to the agent. It involves processing, splitting, and storing documents, questions, or other relevant data in a format that can be efficiently retrieved and used by the language model for answering questions.\n",
    "> - `query()`: This function enables the user to input queries or questions and retrieve answers. It leverages the combined power of the configured LLM, VectorDB, MaxRetriever, and MaxGenerator to search for relevant information and generate accurate, contextually appropriate responses.\n",
    "\n",
    "**Significance and Application**:\n",
    "The MaxAgentQA is a pivotal component for a Data scientist looking to build an efficient and intelligent question-answering agent. By integrating retrieval and generation capabilities, it offers a more dynamic and context-aware approach to handling queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f6f8e-7475-4869-ab26-415fe33ecf34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:01:57.997158Z",
     "iopub.status.busy": "2023-11-21T23:01:57.996642Z",
     "iopub.status.idle": "2023-11-21T23:01:57.999381Z",
     "shell.execute_reply": "2023-11-21T23:01:57.999030Z",
     "shell.execute_reply.started": "2023-11-21T23:01:57.997135Z"
    },
    "tags": []
   },
   "source": [
    "### Step 1 : Initialize the Environment Variables from Config Store\n",
    "\n",
    "The Config Store contains the essential configurations like - \n",
    "- **LLM API Key**: This includes the OPEN_AI_API_KEY, Azure OpenAI, Anthropic Model etc details.\n",
    "- **Vector Database Details**: These details captures the database's user, password, name, port, and other relevant information which are required for setting up and connecting to the vector database.\n",
    "- **MLflow Credentials** : These configurations enables the Max Monitoring capability, using this each individual steps like parameters, artifacts like models, configurations, metrices can be logged and montitored using MLFlow UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c6cbdf-f31f-4598-a0ae-62e938cb8bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T15:35:56.035858Z",
     "iopub.status.busy": "2024-01-30T15:35:56.035505Z",
     "iopub.status.idle": "2024-01-30T15:35:56.411271Z",
     "shell.execute_reply": "2024-01-30T15:35:56.410499Z",
     "shell.execute_reply.started": "2024-01-30T15:35:56.035791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maxairesources.config_store.config_store import ConfigStore\n",
    "config_store = ConfigStore(secrets_manager='max/agents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e3494-d262-4d28-8c83-ca62bf983a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T22:17:24.518091Z",
     "iopub.status.busy": "2023-11-27T22:17:24.517559Z",
     "iopub.status.idle": "2023-11-27T22:17:24.520528Z",
     "shell.execute_reply": "2023-11-27T22:17:24.520030Z",
     "shell.execute_reply.started": "2023-11-27T22:17:24.518072Z"
    },
    "tags": []
   },
   "source": [
    "### Step 2 : MaxFlow - Setting up Monitoring and Logginng\n",
    "\n",
    "**MaxFlow** - \n",
    "We have integrated advanced logging and monitoring features into Max.AI through the MaxFlow accelerator. This pre-built component is designed to meticulously track the entire process of building an agent, here for an instance Question & Answering Agent.\n",
    "\n",
    "Key aspects of MaxFlow include:\n",
    "\n",
    "- **Detailed Logging**: MaxFlow logs every experiment at a granular level. This includes recording each step of the process, ensuring comprehensive documentation of the QnA agent's development.\n",
    "- **Parameter Tracking**: It captures and logs all parameters used in the process, providing clarity on how the agent is configured at each stage.\n",
    "- **Artifact Management**: MaxFlow handles artifacts like models and configurations, logging their usage and changes. This helps in maintaining a track of all components used in the QnA agent’s development.\n",
    "- **Metric Monitoring**: The tool is equipped to log various metrics, offering insights into the performance and efficiency of the QnA agent.\n",
    "- **MLFlow UI Integration**: All these aspects parameters, artifacts, and metrics are accessible and can be monitored through the MLFlow User Interface. This integration allows for an intuitive and user-friendly way to review and analyze the logged information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1651da8f-292d-445e-b07d-851ca6858ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from maxaimetadata.maxflow import MaxFlow\n",
    "mf = MaxFlow(uri = config_store.config_data[\"MAXFLOW_URI\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af71609b-5327-4ffe-86da-ebdaf8d6aa23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T15:36:01.249597Z",
     "iopub.status.busy": "2024-01-30T15:36:01.249104Z",
     "iopub.status.idle": "2024-01-30T15:36:01.841566Z",
     "shell.execute_reply": "2024-01-30T15:36:01.840695Z",
     "shell.execute_reply.started": "2024-01-30T15:36:01.249551Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2024-01-30 15:36:01,432\",\"pid\":\"2031\",\"level\":\"INFO\",\"file_name\":\"1787171647.py\",\"hierarchy\":\"maxaimetadata.maxflow\",\"function_name\":\"<cell line: 1>\",\"line_number\":\"1\",\"message\":\"Successfully set expriment Jan30newEnterpriseQnADemo\",\"extra\":null, \"experiment\": \"NA\",\"run\": \"NA\",\"max_version\": \"NA\"}\n",
      "{\"timestamp\":\"2024-01-30 15:36:01,500\",\"pid\":\"2031\",\"level\":\"INFO\",\"file_name\":\"1787171647.py\",\"hierarchy\":\"maxaimetadata.maxflow\",\"function_name\":\"<cell line: 3>\",\"line_number\":\"3\",\"message\":\"Active run run_id: 22de4a4708a94dcfb2495199a9cb7fb8\",\"extra\":null, \"experiment\": \"Jan30newEnterpriseQnADemo\",\"run\": \"22de4a4708a94dcfb2495199a9cb7fb8\",\"max_version\": \"NA\"}\n",
      "{\"timestamp\":\"2024-01-30 15:36:01,501\",\"pid\":\"2031\",\"level\":\"INFO\",\"file_name\":\"1787171647.py\",\"hierarchy\":\"maxaimetadata.maxflow\",\"function_name\":\"<cell line: 3>\",\"line_number\":\"3\",\"message\":\"Active run name: QnA\",\"extra\":null, \"experiment\": \"Jan30newEnterpriseQnADemo\",\"run\": \"22de4a4708a94dcfb2495199a9cb7fb8\",\"max_version\": \"NA\"}\n",
      "{\"timestamp\":\"2024-01-30 15:36:01,837\",\"pid\":\"2031\",\"level\":\"INFO\",\"file_name\":\"1787171647.py\",\"hierarchy\":\"maxaimetadata.maxflow\",\"function_name\":\"<cell line: 3>\",\"line_number\":\"3\",\"message\":\"Run started successfull\",\"extra\":{\"__maxai_run_type__\": \"QA\", \"__maxai_repo__\": \"https://personalize-ai@dev.azure.com/personalize-ai/max.ai/_git/max.ai.ds.core\", \"__maxai_branch__\": \"feat/maxai_agents\", \"__maxai_commit__\": \"60f1b8ce6e896ecbf4e7f52f3b32864b45974fc0\", \"__maxai_version__\": \"NA\"}, \"experiment\": \"Jan30newEnterpriseQnADemo\",\"run\": \"22de4a4708a94dcfb2495199a9cb7fb8\",\"max_version\": \"NA\"}\n"
     ]
    }
   ],
   "source": [
    "mf.set_experiment(experiment='Experiment-Name',repo_path='.')\n",
    "#create a new run by passing Run name, Type and Description\n",
    "max_run = mf.start_run(name = 'QnA', \n",
    "                   type = 'QA',\n",
    "                   description = 'Max QA Agents')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8827ad-4083-4685-9735-2d121e68df68",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3 : Initialize the MaxAgentQA\n",
    "\n",
    "Here we focus on initializing the MaxAgentQA, a component designed specifically for question-answering tasks.\n",
    "The MaxAgentQA can be fully configurable and can accept the below parameters\n",
    "\n",
    "**Parameter list**\n",
    "- **llm (LLM)**: An instance of a Language Learning Model to be used for text processing.\n",
    "- **chunk_size** (int, optional): The size of text chunks for processing. Defaults to 2000.\n",
    "- **chunk_overlap** (int, optional): The overlap size between consecutive text chunks. Defaults to 200.\n",
    "- **stream** (bool, optional): Flag to indicate if the data should be processed as a stream. Defaults to False.\n",
    "- **collection** (str, optional): The name of the collection to be used in the vector database. If None, initializes later.\n",
    "- **prompt_config** (Dict[str, str], optional): Configuration settings for prompts. If None, an error is raised.\n",
    "- **metadata** (Dict[str, bool], optional): A dictionary to specify which metadata features to include. Defaults to a predefined set.\n",
    "- **embedding_model** (str, optional): The name of the embedding model to be used. Defaults to \"sentence-transformers/all-mpnet-base-v2\".\n",
    "- **retriever_rank** (str, optional): The ranking method to be used by the retriever. Defaults to \"LostInMiddle\".\n",
    "- **generate_method** (str, optional): The method used for generation tasks. Defaults to \"stuff\".\n",
    "- **verbose**(bool, optional) : The parameter sets the verbose parameter for the QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe13139-f52c-4cfd-9b9b-89cc4f26825b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T15:36:01.843231Z",
     "iopub.status.busy": "2024-01-30T15:36:01.842738Z",
     "iopub.status.idle": "2024-01-30T15:36:09.518798Z",
     "shell.execute_reply": "2024-01-30T15:36:09.518148Z",
     "shell.execute_reply.started": "2024-01-30T15:36:01.843203Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB initialized\n",
      "Loaded Anthropic model: claude-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/langchain/llms/anthropic.py:180: UserWarning: This Anthropic LLM is deprecated. Please use `from langchain.chat_models import ChatAnthropic` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from maxaillm.agents.MaxAgentQA import MaxAgentQA\n",
    "\n",
    "agent_qa = MaxAgentQA(\n",
    "                llm_provider = \"anthropic\",\n",
    "                model_name = \"claude-2\",\n",
    "                prompt_config = {'moderations':'','task':'','identity':'', 'output_format': ''}, \n",
    "                collection = \"Collection-Name\", \n",
    "                verbose = True, \n",
    "                vector_store = 'pgvector',\n",
    "                metadata_dict = {'default' : True,\n",
    "                                \"frequent_keywords\" : False, \n",
    "                                \"links\" : True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb650b-1bc9-4369-ac66-31db9213132f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850dd3d-b24c-4480-9bd0-644572c53ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:14:04.002056Z",
     "iopub.status.busy": "2023-11-21T23:14:04.001808Z",
     "iopub.status.idle": "2023-11-21T23:14:04.005263Z",
     "shell.execute_reply": "2023-11-21T23:14:04.004797Z",
     "shell.execute_reply.started": "2023-11-21T23:14:04.002038Z"
    },
    "tags": []
   },
   "source": [
    "#### Step 3.1 : `add()` method\n",
    "\n",
    "It plays a crucial role in processing and managing documents within the MaxAgentQA\n",
    "\n",
    "**Functionalities of add()**:\n",
    "- **Processing a List of Documents**: The method starts by taking in a list of documents. These documents can be in various formats and contain different types of content. Here we use `MaxExtractor`, which parses the files and converts the unstructured formatted document into structured plain text.\n",
    "\n",
    "- **Extracting and Splitting Document Content**: For each document in the list, add() performs extraction and splitting operations. Here we leverage `MaxSplitter`. This involves  splitting this content into smaller chunks based on the document type and semantic understanding. This step is critical for making the data more accessible and easier to analyze.\n",
    "\n",
    "- **Storing Processed Data in VectorDB**: After processing, the `MaxEmbeddings` module stores the resulting data in the vector database using `MaxVectorization`, which is essential for efficient data retrieval and analysis in various machine learning and NLP tasks.\n",
    "\n",
    "- **Return Status**: The method concludes by returning a boolean value indicating the success of the process. It returns True if the processing and storage of documents were successful. Conversely, it returns False if any errors were encountered during the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05de90-3a4d-471d-9d0e-7a22b9603347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [\n",
    "  'path/to/sample.pdf'\n",
    "]\n",
    "\n",
    "agent_qa.add(paths)\n",
    "max_run.log_datasets(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdecaa04-2555-40ea-b92e-d36f369a151a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:15:43.842834Z",
     "iopub.status.busy": "2023-11-21T23:15:43.842595Z",
     "iopub.status.idle": "2023-11-21T23:15:43.845771Z",
     "shell.execute_reply": "2023-11-21T23:15:43.845365Z",
     "shell.execute_reply.started": "2023-11-21T23:15:43.842816Z"
    },
    "tags": []
   },
   "source": [
    "#### Step 3.2 Call Method `query()`\n",
    "\n",
    "It processes a input user query and retrieves the answer along with references.\n",
    "\n",
    "**Functionality of query()**:\n",
    "- **Processing an Input Query**: The method begins by taking an input query from the user. This query is typically in the form of a natural language question or request.\n",
    "\n",
    "- **Retrieving the Answer**: Upon receiving the query, query() processes it to understand its context and intent. The query is passed to `MaxRetriever` which then searches through the stored data in the VectorDB to find the most relevant and accurate answer to the query. The module retrieves relevant chunks for a particular query based on the chosen vector search algorithm. The retrieved chunks are then passed to `MaxGenerator` to generate the output for the user in the desired format.\n",
    "Along with the answer, the method also provides references or sources from which the answer was derived. This is an important aspect, as it adds credibility to the response and allows users to verify the information or explore the topic further.\n",
    "\n",
    "- **Return Format**: The output from this method is the textual response for the query, along with associated references, in the required user format for the user’s understanding and further exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c639a5e-d711-475f-821f-c2905ccc3621",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = agent_qa.query(query= 'Summarize 2022 performance')\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20480377-cfd9-4d36-8f4a-bc388bd0a3d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T06:44:30.964244Z",
     "iopub.status.busy": "2023-11-28T06:44:30.963883Z",
     "iopub.status.idle": "2023-11-28T06:44:30.968280Z",
     "shell.execute_reply": "2023-11-28T06:44:30.967561Z",
     "shell.execute_reply.started": "2023-11-28T06:44:30.964226Z"
    },
    "tags": []
   },
   "source": [
    "### Step 4 Logging the MaxAgentQA\n",
    "\n",
    "- Here we are leveraging MaxFlow logging capability to log the Agent we built above, this agent can be loaded and leveraged by the developer to build applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e6fc9-9276-4b93-800a-f5d7c9a31f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_run.log_agent(agent_qa)\n",
    "\n",
    "max_run.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d33898-0a2d-4164-a482-652e51befa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mf.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea698f7f-0bf3-44a9-ba02-52560a289aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T19:21:20.289157Z",
     "iopub.status.busy": "2023-11-27T19:21:20.288985Z",
     "iopub.status.idle": "2023-11-27T19:21:20.412957Z",
     "shell.execute_reply": "2023-11-27T19:21:20.412392Z",
     "shell.execute_reply.started": "2023-11-27T19:21:20.289134Z"
    },
    "tags": []
   },
   "source": [
    "### The MaxAgentQA is designed to be easily integrated into different software applications. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88abcd3-e07c-4fa8-99f0-7eaadc3baf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
